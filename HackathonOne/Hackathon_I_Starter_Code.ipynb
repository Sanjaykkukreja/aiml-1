{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Hackathon_I_Starter_Code.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.0"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "SZIubkln0AI2"
      },
      "source": [
        "# Advanced Certification in AIML\n",
        "## A Program by IIIT-H and TalentSprint"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "4LNbxek40AI4"
      },
      "source": [
        "# Hackathon : Voice commands based food ordering system\n",
        "The goal of the hacakthon is to train your model on different types of voice data (such as\n",
        "clean studio data, noisy data and finally your own data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "3e0e3sFh0JZJ"
      },
      "source": [
        "### Setup Steps"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xWQwfHmR0MDu",
        "colab": {}
      },
      "source": [
        "#@title Please enter your registration id to start: (e.g. P181900101) { run: \"auto\", display-mode: \"form\" }\n",
        "Id = \"2001488\" #@param {type:\"string\"}\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "RBdFVMDi0Ou0",
        "colab": {}
      },
      "source": [
        "#@title Please enter your password (normally your phone number) to continue: { run: \"auto\", display-mode: \"form\" }\n",
        "password = \"9840689300\" #@param {type:\"string\"}\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "colab_type": "code",
        "id": "Kv0xxq_d0Qb_",
        "outputId": "fa39f14c-b78c-4479-e591-67318f06577c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 450
        }
      },
      "source": [
        "#@title Run this cell to complete the setup for this Notebook\n",
        "\n",
        "from IPython import get_ipython\n",
        "ipython = get_ipython()\n",
        "  \n",
        "notebook=\"BLR_M2_Hackathon\" #name of the notebook\n",
        "\n",
        "def setup():\n",
        "#  ipython.magic(\"sx pip3 install torch\")\n",
        "    ipython.magic(\"sx wget https://cdn.talentsprint.com/aiml/Experiment_related_data/Week8/Hackathon2/Noisy_data.zip\")\n",
        "    ipython.magic(\"sx wget https://cdn.talentsprint.com/aiml/Experiment_related_data/Week8/Hackathon2/studio_data.zip\")\n",
        "    ipython.magic(\"sx wget https://cdn.talentsprint.com/aiml/Experiment_related_data/Week8/Hackathon2/Record_audio.py\")\n",
        "    ipython.magic(\"sx wget https://cdn.talentsprint.com/aiml/Experiment_related_data/Week8/Hackathon2/net_speech_89.pt\")\n",
        "    ipython.magic(\"sx unzip studio_data.zip\")\n",
        "    ipython.magic(\"sx unzip Noisy_data.zip\")\n",
        "    ipython.magic(\"sx pip install torch torchvision\")\n",
        "    ipython.magic(\"sx pip install librosa\")\n",
        "    print (\"Setup completed successfully\")\n",
        "    return\n",
        "\n",
        "def submit_notebook():\n",
        "    \n",
        "    ipython.magic(\"notebook -e \"+ notebook + \".ipynb\")\n",
        "    \n",
        "    import requests, json, base64\n",
        "\n",
        "    url = \"https://dashboard.talentsprint.com/xp/app/save_notebook_attempts\"\n",
        "    if not submission_id:\n",
        "      data = {\"id\" : getId(), \"notebook\" : notebook, \"mobile\" : getPassword()}\n",
        "      r = requests.post(url, data = data)\n",
        "      r = json.loads(r.text)\n",
        "\n",
        "      if r[\"status\"] == \"Success\":\n",
        "          return r[\"record_id\"]\n",
        "      elif \"err\" in r:        \n",
        "        print(r[\"err\"])\n",
        "        return None        \n",
        "      else:\n",
        "        print (\"Something is wrong, the notebook will not be submitted for grading\")\n",
        "        return None\n",
        "\n",
        "    elif getComplexity() and getAdditional() and getConcepts():\n",
        "      f = open(notebook + \".ipynb\", \"rb\")\n",
        "      file_hash = base64.b64encode(f.read())\n",
        "\n",
        "      data = {\"complexity\" : Complexity, \"additional\" :Additional, \n",
        "              \"concepts\" : Concepts, \"record_id\" : submission_id, \n",
        "              \"id\" : Id, \"file_hash\" : file_hash, \"notebook\" : notebook}\n",
        "\n",
        "      r = requests.post(url, data = data)\n",
        "      print(\"Your submission is successful. Ref:\", submission_id)\n",
        "      return submission_id\n",
        "    else: submission_id\n",
        "    \n",
        "\n",
        "def getAdditional():\n",
        "  try:\n",
        "    if Additional: return Additional      \n",
        "    else: raise NameError('')\n",
        "  except NameError:\n",
        "    print (\"Please answer Additional Question\")\n",
        "    return None\n",
        "\n",
        "def getComplexity():\n",
        "  try:\n",
        "    return Complexity\n",
        "  except NameError:\n",
        "    print (\"Please answer Complexity Question\")\n",
        "    return None\n",
        "  \n",
        "def getConcepts():\n",
        "  try:\n",
        "    return Concepts\n",
        "  except NameError:\n",
        "    print (\"Please answer Concepts Question\")\n",
        "    return None\n",
        "\n",
        "def getId():\n",
        "  try: \n",
        "    return Id if Id else None\n",
        "  except NameError:\n",
        "    return None\n",
        "\n",
        "def getPassword():\n",
        "  try:\n",
        "    return password if password else None\n",
        "  except NameError:\n",
        "    return None\n",
        "\n",
        "submission_id = None\n",
        "### Setup \n",
        "if getPassword() and getId():\n",
        "  submission_id = submit_notebook()\n",
        "  if submission_id:\n",
        "    setup()\n",
        "  \n",
        "else:\n",
        "  print (\"Please complete Id and Password cells before running setup\")\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "^C\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-0b22fe13f22b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     92\u001b[0m   \u001b[0msubmission_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubmit_notebook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0msubmission_id\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m     \u001b[0msetup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-12-0b22fe13f22b>\u001b[0m in \u001b[0;36msetup\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m#  ipython.magic(\"sx pip3 install torch\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mipython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmagic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"sx wget https://cdn.talentsprint.com/aiml/Experiment_related_data/Week8/Hackathon2/Noisy_data.zip\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mipython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmagic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"sx wget https://cdn.talentsprint.com/aiml/Experiment_related_data/Week8/Hackathon2/studio_data.zip\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mipython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmagic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"sx wget https://cdn.talentsprint.com/aiml/Experiment_related_data/Week8/Hackathon2/Record_audio.py\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mipython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmagic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"sx wget https://cdn.talentsprint.com/aiml/Experiment_related_data/Week8/Hackathon2/net_speech_89.pt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mmagic\u001b[0;34m(self, arg_s)\u001b[0m\n\u001b[1;32m   2158\u001b[0m         \u001b[0mmagic_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmagic_arg_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marg_s\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartition\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2159\u001b[0m         \u001b[0mmagic_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmagic_name\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprefilter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mESC_MAGIC\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2160\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2162\u001b[0m     \u001b[0;31m#-------------------------------------------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_line_magic\u001b[0;34m(self, magic_name, line)\u001b[0m\n\u001b[1;32m   2079\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'local_ns'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_locals\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2080\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2081\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2082\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2083\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m</usr/local/lib/python3.6/dist-packages/decorator.py:decorator-gen-99>\u001b[0m in \u001b[0;36msx\u001b[0;34m(self, line, cell)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/magics/osm.py\u001b[0m in \u001b[0;36msx\u001b[0;34m(self, line, cell)\u001b[0m\n\u001b[1;32m    659\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcell\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    660\u001b[0m             \u001b[0;31m# line magic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 661\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetoutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    662\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    663\u001b[0m             \u001b[0mopts\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_options\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'out='\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/_shell.py\u001b[0m in \u001b[0;36mgetoutput\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     77\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mShell\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetoutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_system_commands\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getoutput_compat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint:disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_show_pip_warning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0m_pip\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_pip_install_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/_system_commands.py\u001b[0m in \u001b[0;36m_getoutput_compat\u001b[0;34m(shell, cmd, split, depth)\u001b[0m\n\u001b[1;32m    398\u001b[0m   \u001b[0;31m# stack.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m   result = _run_command(\n\u001b[0;32m--> 400\u001b[0;31m       shell.var_expand(cmd, depth=depth + 2), clear_streamed_output=True)\n\u001b[0m\u001b[1;32m    401\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_INTERRUPTED_SIGNALS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'^C'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/_system_commands.py\u001b[0m in \u001b[0;36m_run_command\u001b[0;34m(cmd, clear_streamed_output)\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m     with temporary_clearer(), _display_stdin_widget(\n\u001b[0;32m--> 181\u001b[0;31m         delay_millis=500) as update_stdin_widget:\n\u001b[0m\u001b[1;32m    182\u001b[0m       \u001b[0;31m# TODO(b/115531839): Ensure that subprocesses are terminated upon\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m       \u001b[0;31m# interrupt.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/contextlib.py\u001b[0m in \u001b[0;36m__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"generator didn't yield\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/_system_commands.py\u001b[0m in \u001b[0;36m_display_stdin_widget\u001b[0;34m(delay_millis)\u001b[0m\n\u001b[1;32m    339\u001b[0m   \u001b[0mshell\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_ipython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m   \u001b[0mdisplay_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'cell_display_stdin'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'delayMillis'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdelay_millis\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 341\u001b[0;31m   \u001b[0m_message\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocking_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mdisplay_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparent_header\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    342\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mecho_updater\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_echo_status\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    169\u001b[0m   \u001b[0;31m# unique.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m   \u001b[0mrequest_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msend_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_read_next_input_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_NOT_READY\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m       \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.025\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m       \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m     if (reply.get('type') == 'colab_reply' and\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DqNBNvC25WNV",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from torch.autograd import Variable\n",
        "import numpy as np\n",
        "import librosa\n",
        "import os\n",
        "import warnings\n",
        "from time import sleep\n",
        "import sys\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "wqMmxLR38vJ3"
      },
      "source": [
        "## Pretrained Network for deep features\n",
        "\n",
        "\n",
        "The following function contains code to load a pre-trained network to produces deep features for the audio sample. This network is trained with delta MFCC features of mono channel 8000 bit rate audio sample."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "NDbuxUiL2zYL",
        "colab": {}
      },
      "source": [
        "def get_network():\n",
        "\n",
        "    net = torch.nn.Sequential()\n",
        "\n",
        "    saved_net = torch.load(\"net_speech_89.pt\").cpu()\n",
        "\n",
        "    for index, module in enumerate(saved_net):\n",
        "        net.add_module(\"layer\"+str(index),module)\n",
        "        if (index+1)%17 == 0 :\n",
        "            break\n",
        "    return net"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "dmoIgxTG5ZnF",
        "outputId": "063ed3b8-dc99-4c48-a9f0-072e9c2d857f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        }
      },
      "source": [
        "get_network()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (layer0): Linear(in_features=900, out_features=800, bias=True)\n",
              "  (layer1): ReLU()\n",
              "  (layer2): Linear(in_features=800, out_features=700, bias=True)\n",
              "  (layer3): ReLU()\n",
              "  (layer4): Linear(in_features=700, out_features=600, bias=True)\n",
              "  (layer5): ReLU()\n",
              "  (layer6): Linear(in_features=600, out_features=500, bias=True)\n",
              "  (layer7): ReLU()\n",
              "  (layer8): Linear(in_features=500, out_features=400, bias=True)\n",
              "  (layer9): ReLU()\n",
              "  (layer10): Linear(in_features=400, out_features=300, bias=True)\n",
              "  (layer11): ReLU()\n",
              "  (layer12): Linear(in_features=300, out_features=200, bias=True)\n",
              "  (layer13): ReLU()\n",
              "  (layer14): Linear(in_features=200, out_features=100, bias=True)\n",
              "  (layer15): ReLU()\n",
              "  (layer16): Linear(in_features=100, out_features=50, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "sZS1NA1sATEf"
      },
      "source": [
        "##Obtaining Features from Audio samples\n",
        "Generate features from a audio sample of '.wav' format\n",
        "* Generate Delta MFCC features of order 1 and 2 \n",
        "* Passes them through the above mentioned deep neural net\n",
        "* the obtained deep features are returned\n",
        "\n",
        "Parameters: Filepath (path of audio sample),\n",
        "                       sr (sampling rate, all the samples provided are of 8000 bitrate)\n",
        "         \n",
        "  Caution: Do not change the default parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "eTtb2zAj5k0-",
        "colab": {}
      },
      "source": [
        "def get_features(filepath, sr=8000, n_mfcc=30, n_mels=128, frames = 15):\n",
        "    \n",
        "    \n",
        "    y, sr = librosa.load(filepath, sr=sr)\n",
        "    D = np.abs(librosa.stft(y))**2\n",
        "    S = librosa.feature.melspectrogram(S=D)\n",
        "    S = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=n_mels)\n",
        "    log_S = librosa.power_to_db(S,ref=np.max)\n",
        "    features = librosa.feature.mfcc(S=log_S, n_mfcc=n_mfcc)\n",
        "    if features.shape[1] < frames :\n",
        "        features = np.hstack((features, np.zeros((n_mfcc, frames - features.shape[1]))))\n",
        "    elif features.shape[1] > frames:\n",
        "        features = features[:, :frames]\n",
        "    # Find 1st order delta_mfcc\n",
        "    delta1_mfcc = librosa.feature.delta(features, order=1)\n",
        "\n",
        "    # Find 2nd order delta_mfcc\n",
        "    delta2_mfcc = librosa.feature.delta(features, order=2)\n",
        "    features = np.hstack((delta1_mfcc.flatten(), delta2_mfcc.flatten()))\n",
        "    features = features.flatten()[np.newaxis, :]\n",
        "    features = Variable(torch.from_numpy(features)).float()\n",
        "    deep_net = get_network()\n",
        "    deep_features = deep_net(features)\n",
        "    #print(features.shape)\n",
        "    #print(audio_file)\n",
        "    #features.flatten()[np.newaxis, :]\n",
        "    return deep_features.data.numpy().flatten()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "NhLFY4n6BwIj"
      },
      "source": [
        "## All the voice sample needed for training are present across the folders \"Noisy_data\" and \"studio_data\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lMF1AqHZhl1h",
        "colab_type": "code",
        "outputId": "c92fde2d-3caa-494e-c6b5-723a6af8aa8a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        }
      },
      "source": [
        "%ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "BLR_M2_Hackathon.ipynb        \u001b[0m\u001b[01;34mNoisy_data\u001b[0m/              \u001b[01;34msample_data\u001b[0m/\n",
            "\u001b[01;34m__MACOSX\u001b[0m/                     noisy_data_features.sav  \u001b[01;34mstudio_data\u001b[0m/\n",
            "mlp_trained_model_noise.clf   noisy_data_labels.sav    studio_data_features.sav\n",
            "mlp_trained_model_studio.clf  Noisy_data.zip           studio_data_labels.sav\n",
            "net_speech_89.pt              Record_audio.py          studio_data.zip\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "SB-LowDuCMUL"
      },
      "source": [
        "##Stage 1: Loading data (5 Marks)\n",
        "\n",
        "* Load 'Studio data' and extract features from the data\n",
        "\n",
        "### Evaluation Criteria: \n",
        "* Complete the code in the load_data function\n",
        "* The function should take path of the folder containing audio samples as input\n",
        "* It should return features of all the audio samples present in the specified folder into single array (list of lists or 2-d numpy array) and their respective labels should be returned too"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "qDzCa-532EUj",
        "colab": {}
      },
      "source": [
        "import glob\n",
        "def load_files(folder_path):\n",
        "  labels = []\n",
        "  wav_files = []\n",
        "  features = []\n",
        "  # This loop is to store the labels and filenames into list\n",
        "  for filename in glob.iglob(folder_path + '/*.wav'):\n",
        "    # Store the labels of each wav file in a list\n",
        "    labels.append(int((filename.split('/')[-1]).split('_')[0]))\n",
        "    # Store the wav files in a list\n",
        "    wav_files.append(filename)\n",
        "  # This Loop is to get features and store into features list\n",
        "  for filename in wav_files:\n",
        "    features.append(get_features(filename))\n",
        "  return np.asarray(features), np.asarray(labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z5CG-d_yhpHX",
        "colab_type": "code",
        "outputId": "616c1d50-ce5e-4e1a-b775-9822d4a81a55",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!pwd"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tnpuucBwbpl1",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7673ezpxFEfM"
      },
      "source": [
        "####load data and labels from studio_data folder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "u5CjrlPVPjNs",
        "outputId": "b4437e51-54ee-44d8-b964-9e0ed378683a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "studio_recorded_features, studio_recorded_labels = load_files('studio_data')\n",
        "print(studio_recorded_features.shape, studio_recorded_labels.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(8423, 50) (8423,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sRsizBC6_aIf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import joblib\n",
        "studio_recorded_features, studio_recorded_labels = np.asarray(joblib.load('studio_data_features.sav')),np.asarray(joblib.load('studio_data_labels.sav'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7QNqBhLE3LkE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "joblib.dump(studio_recorded_features, 'studio_data_features.sav')               # Command to save the model file\n",
        "joblib.dump(studio_recorded_labels, 'studio_data_labels.sav')\n",
        "\n",
        "files.download(\"studio_data_features.sav\")                                      # Download the model file to local PC\n",
        "files.download(\"studio_data_labels.sav\")                                        # Download the model file to local PC"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mP-4epdLzaC-",
        "colab_type": "code",
        "outputId": "4c1718c4-e520-4dae-a1fb-f56870e31900",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "studio_recorded_features.shape, studio_recorded_labels.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((8423, 50), (8423,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "BGq6XpvhFynP"
      },
      "source": [
        "## Stage 2: Training classifier on the studio_data (16 Marks)\n",
        "* The goal here is to train your model on voice samples collected in a noiseless studio\n",
        "setup above\n",
        "\n",
        "### Evaluation Criteria: \n",
        "* Train the classifier, save the model\n",
        "* The score you get: Validation accuracy percentage of 15 (Validation data should be at\n",
        "least 20% of the total data)\n",
        "* Example: If a team gets, 80 % accuracy on the validation set, then the marks will be\n",
        "80% of 15 marks i.e. 12 marks (will round of the score, in case of non - integer scores) and deploy the (refer colab notebook)\n",
        "\n",
        "#### Train a classifier on the features obtained from studio_data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VU5hdERsFw5o",
        "outputId": "6f59e6fa-552d-4c70-a1af-a195f11791bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Import train_test_split header\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split files for training and testing (80:20)\n",
        "X_train, X_test, y_train, y_test = train_test_split(studio_recorded_features, studio_recorded_labels, test_size=0.2, random_state=43)\n",
        "\n",
        "# Train the Data as a numpy array\n",
        "X_train = np.array(X_train) \n",
        "y_train = np.array(y_train)\n",
        "X_train.shape, y_train.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((6738, 50), (6738,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Gyhg3hiecu5",
        "colab_type": "text"
      },
      "source": [
        "### Use the above data and train using MLPClassifier:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l4LpU0b3eWer",
        "colab_type": "code",
        "outputId": "038dddd4-dcdd-48d6-e786-78a02815b15f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        }
      },
      "source": [
        "# Import Necessary Headers\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "# Train the data\n",
        "clf = MLPClassifier(random_state = 12)\n",
        "clf.fit(X_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
              "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
              "              hidden_layer_sizes=(100,), learning_rate='constant',\n",
              "              learning_rate_init=0.001, max_fun=15000, max_iter=200,\n",
              "              momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
              "              power_t=0.5, random_state=12, shuffle=True, solver='adam',\n",
              "              tol=0.0001, validation_fraction=0.1, verbose=False,\n",
              "              warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DKVXqe4l51kE",
        "colab_type": "code",
        "outputId": "15033206-7a0d-46de-f658-9030ab36d0fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        }
      },
      "source": [
        "\n",
        "# Import Necessary Headers\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "# Train the data\n",
        "clf = joblib.load('mlp_trained_model_studio.clf')\n",
        "clf.fit(X_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
              "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
              "              hidden_layer_sizes=(100,), learning_rate='constant',\n",
              "              learning_rate_init=0.001, max_fun=15000, max_iter=200,\n",
              "              momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
              "              power_t=0.5, random_state=41, shuffle=True, solver='adam',\n",
              "              tol=0.0001, validation_fraction=0.1, verbose=False,\n",
              "              warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5NxlvFcOiu9f",
        "colab_type": "text"
      },
      "source": [
        "### Use this to predict accuracy for the trained model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dkOPxjEgilhV",
        "colab_type": "code",
        "outputId": "c972ab91-9855-4c7e-f844-9a141493063b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Import necessary headers\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Save the predicted values in a variable\n",
        "predicted_values = clf.predict(np.array(X_test))\n",
        "\n",
        "# Predict Accuracy score (in %)\n",
        "accuracy_score(np.array(y_test),predicted_values)*100"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "88.24925816023739"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "OGixO_z6Gf-Y"
      },
      "source": [
        "####Save your model\n",
        "\n",
        "Hint:\n",
        "* Incase if you are using scikit learn model for training, you can use joblib package to save the model.\n",
        "* Manually implemented models as a function or class can be saved using pickle "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ut8aQN5_G7bx",
        "outputId": "1d54075d-3639-4d3c-f798-e5c6c769f04a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import joblib                         # Import Necessary Headers\n",
        "\n",
        "file = 'mlp_trained_model_studio.clf' # Specify filename of model file\n",
        "joblib.dump(clf, file)                # Command to save the model file"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['mlp_trained_model_studio.clf']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QWUSGj8bj-iQ",
        "colab_type": "code",
        "outputId": "0ef57e28-b2db-4820-d4d2-3bc98b58bf42",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%ls -F $file                          # Check if the created model file exists!"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MLP_trained_model_studio.clf\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "jsCHKXubHAJB"
      },
      "source": [
        "#### Download your trained model using the code below\n",
        "* given the path of model file the following code downloads it through the browser"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BDmWXfPaHJZG",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "files.download(file)                  # Download the model file to local PC"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "R7ccsM_ZISWj"
      },
      "source": [
        "## Stage 3: Deploy your classifier on the server (3 Marks)\n",
        "\n",
        "* Deploy your model on the server, check the deployment instructions in the hackathon documentation for details\n",
        "\n",
        "### Evaluation Criteria: \n",
        "\n",
        "* There are two stages in the food ordering application\n",
        "        \n",
        "    *   Ordering Item\n",
        "    *   Providing the number of servings\n",
        "    \n",
        "* If both the stages are cleared with correct predictions you will get\n",
        "complete marks\n",
        "* Otherwise, no marks will be awarded\n",
        "\n",
        "\n",
        "\n",
        "#### Now deploy the model trained on studio_data in the sever to order food correctly. \n",
        "#### Deployment instruction are given in the Hackathon documentation\n",
        "#### After deploying and checking the application come back here to train on Noisy_data to generalise better in real situations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WZhvgJQZpAxk",
        "colab_type": "text"
      },
      "source": [
        "## Stage 4: Load 'Noisy_data', train a Classifier on the same and deploy (3 Marks)\n",
        "\n",
        "* The goal here is to train your model on voice samples collected in a noisy environment and save the model\n",
        "\n",
        "### Evaluation Criteria:\n",
        "\n",
        "* Load 'Noisy_data'\n",
        "* Train the classifier, save the model\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "VFOudw7XGDeQ"
      },
      "source": [
        "#### load data and labels from Noisy_data folder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5LLejdkbCat2",
        "colab": {}
      },
      "source": [
        "noisy_data, noisy_data_labels = load_files('Noisy_data')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z-J-1NvlhwZD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "noisy_data, noisy_data_labels = np.asarray(joblib.load('noisy_data_features.sav')),np.asarray(joblib.load('noisy_data_labels.sav'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_m24s9eFLVCX",
        "colab_type": "code",
        "outputId": "a4d819f8-394c-4410-c4ae-89334204501f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "noisy_data.shape, noisy_data_labels.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((11839, 50), (11839, 1))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pYAcLvBDkgnL",
        "colab_type": "code",
        "outputId": "aaea4149-740d-4ad8-87f2-17ea8bdab640",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "type(noisy_data_labels)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HYK88qmLgzwc",
        "colab_type": "text"
      },
      "source": [
        "#### Train a classifier on the features obtained from noisy_data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Kb2vC8orK8_",
        "colab_type": "code",
        "outputId": "029db25a-3775-4164-a17c-9c0603e1eeb7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Split noise files for training and testing (80:20)\n",
        "X_noise_train, X_noise_test, y_noise_train, y_noise_test = train_test_split(noisy_data, noisy_data_labels, test_size=0.2)\n",
        "\n",
        "# Transform the Data as a numpy array and check shape\n",
        "X_noise_train = np.array(X_noise_train) \n",
        "y_noise_train = np.array(y_noise_train)\n",
        "X_noise_train.shape, y_noise_train.shape\n",
        "\n",
        "# Train the data\n",
        "clf_noise = MLPClassifier(random_state = 60)\n",
        "clf_noise.fit(X_noise_train, y_noise_train)\n",
        "\n",
        "# Save the predicted values in a variable\n",
        "predicted_noise_values = clf_noise.predict(np.array(X_noise_test))\n",
        "\n",
        "# Predict Accuracy score (in %)\n",
        "accuracy_score(np.array(y_noise_test),predicted_noise_values)*100"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "29.43412162162162"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E2jfdJigrTkr",
        "colab_type": "text"
      },
      "source": [
        "####Save your model\n",
        "\n",
        "Hint:\n",
        "* Incase if you are using scikit learn model for training, you can use joblib package to save the model.\n",
        "* Manually implemented models as a function or class can be saved using pickle "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GJBkPlNUrhbz",
        "colab_type": "code",
        "outputId": "f4cf4575-f567-41a2-b469-ffc9d2e4be72",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "noise_model_file = 'mlp_trained_model_noise.clf'        # Specify filename of model file\n",
        "joblib.dump(clf_noise, noise_model_file)                # Command to save the model file"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['mlp_trained_model_noise.clf']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q9nlF00Q7iff",
        "colab_type": "code",
        "outputId": "35afd66e-6f47-4a4e-acb1-168db14b1272",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%ls -F $noise_model_file                                # Check if the created model file exists!"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mlp_trained_model_noise.clf\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7T3v5XQbron7",
        "colab_type": "text"
      },
      "source": [
        "#### Download your trained model using the code below\n",
        "* given the path of model file the following code downloads it through the browser"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sNhSG65BrqAm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "files.download(noise_model_file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TwXw75OlrzJ8",
        "colab_type": "text"
      },
      "source": [
        "#### Now deploy the model trained on noisy_data in the sever to order food correctly."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kA6G5tzShN5s",
        "colab_type": "text"
      },
      "source": [
        "## Stage 5: Use 'Noisy_data' and 'Studio-data' together, train a Classifier on the same and deploy (3 Marks)\n",
        "\n",
        "* The goal here is to train your model on voice samples collected in a noisy environment 'and' studio-data save the model\n",
        "\n",
        "### Evaluation Criteria:\n",
        "\n",
        "* Use the 'Noisy_data' and 'studio-data' loaded above and train the classifier, save the model\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "wPmAbksHGK0a"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "#### Train a classifier on the features obtained from both the Noisy_data and Studio_data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yFclsavsngre",
        "colab_type": "code",
        "outputId": "459f375b-c752-4cae-f22b-6eb73c17678a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "studio_recorded_labels.shape, noisy_data_labels.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((8423,), (11839, 1))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XyZ16AUKGeoN",
        "outputId": "db871f55-6f8c-4ce5-ec10-1bff5f9eb8af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Concatinate both Studio and Noisy data to all data\n",
        "all_features = np.vstack((studio_recorded_features, noisy_data))\n",
        "all_labels = np.vstack((studio_recorded_labels.reshape(8423,1), noisy_data_labels))\n",
        "\n",
        "# Split noise files for training and testing (80:20)\n",
        "X_all_train, X_all_test, y_all_train, y_all_test = train_test_split(all_features, all_labels, test_size=0.2)\n",
        "\n",
        "# Transform the Data as a numpy array and check shape\n",
        "X_all_train = np.array(X_noise_train) \n",
        "y_all_train = np.array(y_noise_train)\n",
        "X_all_train.shape, y_all_train.shape\n",
        "\n",
        "# Train the data\n",
        "clf_all = MLPClassifier()\n",
        "clf_all.fit(X_all_train, y_all_train)\n",
        "\n",
        "# Save the predicted values in a variable\n",
        "predicted_all_values = clf_all.predict(np.array(X_all_test))\n",
        "accuracy_score(np.array(y_all_test),predicted_all_values)*100"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "55.662472242783124"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y4IbSzHAsqWT",
        "colab_type": "text"
      },
      "source": [
        "####Save your model\n",
        "\n",
        "Hint:\n",
        "* Incase if you are using scikit learn model for training, you can use joblib package to save the model.\n",
        "* Manually implemented models as a function or class can be saved using pickle "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4PZQ-jrPsreD",
        "colab_type": "code",
        "outputId": "d7f06af1-9e79-45ce-e1c7-2be9abed7467",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "all_model_file = 'mlp_trained_model_all.clf'        # Specify filename of model file\n",
        "joblib.dump(clf_all, all_model_file)                # Command to save the model file"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['mlp_trained_model_all.clf']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "wJlS0qjmIEYz"
      },
      "source": [
        "#### Download your trained model using the code below\n",
        "* given the path of model file the following code downloads it through the browser"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "mUM_6cP-IJy5",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "files.download(all_model_file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "jA829HXjIe5Z"
      },
      "source": [
        "#### Now deploy the model trained on above in the sever to order food correctly. \n",
        "#### Deployment instruction are given the Hackathon documentation\n",
        "#### After deploying and checking the application, record your teams data from the web application provided in the Hackathon document"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nv3I24flWlLq",
        "colab": {}
      },
      "source": [
        "!mkdir teamdata"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "TWrJSY-OGyG9"
      },
      "source": [
        "#### Replace <YOUR_GROUP_ID> with your group id given in the lab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gB_bSllKWJ5U",
        "colab": {}
      },
      "source": [
        "!wget -r -A .wav https://aiml-sandbox1.talentsprint.com/audio_recorder/<YOUR_GROUP_ID>/team_data/ -nH --cut-dirs=100  -P ./team_data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3XUPRHG50rxW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%ls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zU556OeCL0x9",
        "colab": {}
      },
      "source": [
        "!unzip <zip_file_name>"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "wH17k1RciuM_"
      },
      "source": [
        "## Stage 6: Collect the voice samples and refine the classifier trained on noisy_data, by now using your teams data (10 Marks)\n",
        "\n",
        "\n",
        "* The goal here is to refine the model that you trained on voice samples collected\n",
        "in a noisy environment\n",
        "* You will refine your model trained on noisy_data, save and download it.\n",
        "* Deploy your model on the server, check deployment section in the same\n",
        "document for details\n",
        "\n",
        "### Evaluation Criteria:\n",
        "* There are two stages in the food ordering application\n",
        "\n",
        "    *   Ordering Item\n",
        "    *   Providing the number of servings\n",
        "\n",
        "* If both the stages are cleared with correct predictions you will get complete marks\n",
        "* Otherwise, no marks will be awarded\n",
        "\n",
        "#### Enhance the model trained with both the noisy data and studio_data to your team's voice samples"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "cwKko3-yL-0a",
        "colab": {}
      },
      "source": [
        "##YOUR CODE HERE"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "zQhiuXMaMRp2"
      },
      "source": [
        "####  Now deploy the model trained above in the sever to order food correctly. \n",
        "#### Deployment instruction are given the Hackathon documentation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "jx6Y0Roy19a0"
      },
      "source": [
        "### Please answer the questions below to complete the experiment:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-O68_f5E2Az_",
        "colab": {}
      },
      "source": [
        "#@title How was the experiment? { run: \"auto\", form-width: \"500px\", display-mode: \"form\" }\n",
        "Complexity = \"\" #@param [\"\",\"Too Simple, I am wasting time\", \"Good, But Not Challenging for me\", \"Good and Challenging me\", \"Was Tough, but I did it\", \"Too Difficult for me\"]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4YpxQ61Q2CjX",
        "colab": {}
      },
      "source": [
        "#@title If it was very easy, what more you would have liked to have been added? If it was very difficult, what would you have liked to have been removed? { run: \"auto\", display-mode: \"form\" }\n",
        "Additional = \"\" #@param {type:\"string\"}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "QZWB9A6M2Fuv",
        "colab": {}
      },
      "source": [
        "#@title Can you identify the concepts from the lecture which this experiment covered? { run: \"auto\", vertical-output: true, display-mode: \"form\" }\n",
        "Concepts = \"\" #@param [\"\",\"Yes\", \"No\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "colab_type": "code",
        "id": "03H962QV2Haz",
        "colab": {}
      },
      "source": [
        "#@title Run this cell to submit your notebook for grading { vertical-output: true }\n",
        "try:\n",
        "  if submission_id:\n",
        "      return_id = submit_notebook()\n",
        "      if return_id : submission_id =return_id\n",
        "  else:\n",
        "      print(\"Please complete the setup first.\")\n",
        "except NameError:\n",
        "  print (\"Please complete the setup first.\")"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}