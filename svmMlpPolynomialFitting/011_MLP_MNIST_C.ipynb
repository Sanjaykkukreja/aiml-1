{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1_Syoy6MnWmR"
   },
   "source": [
    "\n",
    "# Advanced Certification in AIML\n",
    "## A Program by IIIT-H and TalentSprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mY4lunPOojoT"
   },
   "source": [
    "## Learning Objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VPDGLSN8omMi"
   },
   "source": [
    "At the end of the experiment, you will be able to :\n",
    "\n",
    "* understand Multi-Layer Perceptron (MLP)\n",
    "* tune the hyper-parameters of a MLP classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rhfkgZga3yR3"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0W6B70KcpMKv"
   },
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "boHywfVQpSOe"
   },
   "source": [
    "###Description\n",
    "\n",
    "We use the MNIST dataset for this experiment. Below are the details:\n",
    "\n",
    "1. The dataset contains 60,000 Handwritten digits as training samples and 10,000 Test samples, \n",
    "which means each digit occurs 6000 times in the training set and 1000 times in the testing set. (approximately). \n",
    "2. Each image is Size Normalized and Centered \n",
    "3. Each image is 28 X 28 Pixel with 0-255 Gray Scale Value. \n",
    "4. That means each image is represented as 784 (28 X28) dimension vector where each value is in the range 0- 255.\n",
    "\n",
    "### History\n",
    "\n",
    "Yann LeCun (Director of AI Research, Facebook, Courant Institute, NYU) was given the task of identifying the cheque numbers (in the 90’s) and the amount associated with that cheque without manual intervention. That is when this dataset was created which raised the bars and became a benchmark.\n",
    "\n",
    "Yann LeCun and Corinna Cortes (Google Labs, New York) hold the copyright of MNIST dataset, which is a subset of the original NIST datasets. This dataset is made available under the terms of the Creative Commons Attribution-Share Alike 3.0 license. \n",
    "\n",
    "It is the handwritten digits dataset in which half of them are written by the Census Bureau employees and remaining by the high school students. The digits collected among the Census Bureau employees are easier and cleaner to recognize than the digits collected among the students.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "v996o70VpXd7"
   },
   "source": [
    "## Domain Information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lSn393pspZrQ"
   },
   "source": [
    "\n",
    "Handwriting changes person to person. Some of us have neat handwriting and some have illegible handwriting such as doctors. However, if you think about it even a child who recognizes alphabets and numerics can identify the characters of a text even written by a stranger. But even a technically knowledgeable adult cannot describe the process by which he or she recognizes the text/letters. As you know this is an excellent challenge for Machine Learning.\n",
    "\n",
    "![altxt](https://i.pinimg.com/originals/f2/7a/ac/f27aac4542c0090872110836d65f4c99.jpg)\n",
    "\n",
    "The experiment handles a subset of text recognition, namely recognizing the 10 numerals (0 to 9) from scanned images.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vGTs_Q8T3AL7"
   },
   "source": [
    "##AI/ML Technique\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iNpSnff_nWmW"
   },
   "source": [
    "A hyperparameter is a parameter whose value is set before the learning process begins."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-Ppa_jkQ3B0Z"
   },
   "source": [
    "### What is  MLP ?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "O-NXCwYT3LsF"
   },
   "source": [
    "A multilayer perceptron is a class of feedforward artificial neural network. An MLP consists of, at least, three layers of nodes as shown in below image: \n",
    "\n",
    "**Layer1** :   Input Layer\n",
    "\n",
    "**Layer 2** :  Hidden Layer\n",
    "\n",
    "**Layer 3** : Output Layer\n",
    "\n",
    "![alt text](https://www.researchgate.net/profile/Mohamed_Zahran6/publication/303875065/figure/fig4/AS:371118507610123@1465492955561/A-hypothetical-example-of-Multilayer-Perceptron-Network.png)\n",
    "\n",
    "The number of nodes in the input layer is determined by the dimensionality of our data. \n",
    "\n",
    "The number of nodes in the output layer is determined by the number of classes we have.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oO41uG3oWviH"
   },
   "source": [
    "### Keywords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "op1cElyCWyZp"
   },
   "source": [
    "**activation :** \n",
    "\n",
    "*  identity \n",
    "* logistic  \n",
    "* tanh \n",
    "* relu \n",
    "\n",
    "\n",
    "**  Solvers :** \n",
    "\n",
    "* lbfgs\n",
    "* sgd\n",
    "* adam\n",
    "  \n",
    "  \n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "s1OKA4xynWmX"
   },
   "source": [
    "#### Importing the required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "v_g-vhFCnWmY"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "92sr2eUf0Y9l"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3RLdLj8GnWmd"
   },
   "source": [
    "Loading the dataset from sklearn package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-rusMmbLnWmf"
   },
   "outputs": [],
   "source": [
    "#Load MNIST datset \n",
    "digits = datasets.load_digits(n_class=10)\n",
    "# Create our X and y data\n",
    "data = digits.data\n",
    "target = digits.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "seX_QbLrj4XN",
    "outputId": "684b967c-4bf3-4baf-851f-bfa4341f953a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1797, 64), (1797,))"
      ]
     },
     "execution_count": 12,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape, target.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Biy6C3CM0Bd9"
   },
   "source": [
    "## You could be wondering why data shape is 1797 above, when MNIST is a 60k training and 10k testing dataset?\n",
    " \n",
    "Well, the original dataset takes time to run thus delaying your observations and learning of the MLP classifier. You are however free to experiment by replacing the line <br/>\n",
    "**digits = datasets.load_digits(n_class=10)**  in the cell above, with the following: <br/>\n",
    "\n",
    "<br/>\n",
    "<br/>\n",
    "**from sklearn.datasets import fetch_openml <br/>\n",
    "digits = fetch_openml('mnist_784')** <br/>\n",
    "\n",
    "However please be aware that this program might run for a really long time !! \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8srwHyGFnWml"
   },
   "source": [
    "\n",
    "\n",
    "Split  data into training ,testing  sets. This is done easily with SciKit Learn’s train_test_split function.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7QyTcVXadQV9"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Rd2caLjnnWml"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test =  train_test_split(data, target, test_size=0.2, random_state=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JUOCABqynWmq"
   },
   "outputs": [],
   "source": [
    "#function to Create MLP classifier object with hyper parameters\n",
    "def mlp(a,s,h,lr):\n",
    "    clf = MLPClassifier(activation= a ,solver= s ,hidden_layer_sizes = h,max_iter = 5000 ,learning_rate = 'constant',learning_rate_init=lr)\n",
    "    return clf \n",
    "#function to calculate the accuracy\n",
    "def accuracy(actual,predicted):\n",
    "    return accuracy_score(actual,predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "N0OwqiyQnWmt"
   },
   "source": [
    "**Let us define the hyper parameters of MLP Classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3RGkGdvSnWmv"
   },
   "outputs": [],
   "source": [
    "# activation: Activation functions are critical in introducing non-linearity in MLP (in absence of this all layers of MLP combine into a single layer)\n",
    "activation = [\"identity\",\"logistic\",\"tanh\",\"relu\"]\n",
    "#solvers: The following are the methods by which your weights get updated.\n",
    "solvers = [\"lbfgs\",\"sgd\",\"adam\"]\n",
    "#learning rate\n",
    "learning_rate = [0.0001,0.001,0.01,0.1]\n",
    "#hidden layers\n",
    "hidden_layers = [(5,2),(3,2),(6,3),(7,2)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HDkAAEe60_9-"
   },
   "source": [
    "In the below code cell we are trying to train a MLP classifer with different hyper parameters. Here we choose a random index value based on size of the hyper parameters list which are defined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "UoChIOiunWm1",
    "outputId": "84954219-5473-4567-a6f7-0b12c15d7551"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Hyper-parameters = \n",
      " activation =  logistic \n",
      " solver =  lbfgs \n",
      " learning_rate_init =  0.1 \n",
      " hidden_layer_sizes =  (6, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(train,  test) accuracy =  0.8517745302713987 0.7583333333333333\n",
      "\n",
      "Hyper-parameters = \n",
      " activation =  tanh \n",
      " solver =  sgd \n",
      " learning_rate_init =  0.001 \n",
      " hidden_layer_sizes =  (6, 3)\n",
      "(train,  test) accuracy =  0.7571329157967989 0.6666666666666666\n",
      "\n",
      "Hyper-parameters = \n",
      " activation =  identity \n",
      " solver =  adam \n",
      " learning_rate_init =  0.0001 \n",
      " hidden_layer_sizes =  (3, 2)\n",
      "(train,  test) accuracy =  0.720946416144746 0.7305555555555555\n",
      "\n",
      "Hyper-parameters = \n",
      " activation =  identity \n",
      " solver =  lbfgs \n",
      " learning_rate_init =  0.0001 \n",
      " hidden_layer_sizes =  (5, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(train,  test) accuracy =  0.8197633959638135 0.8\n",
      "\n",
      "Hyper-parameters = \n",
      " activation =  logistic \n",
      " solver =  lbfgs \n",
      " learning_rate_init =  0.01 \n",
      " hidden_layer_sizes =  (3, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(train,  test) accuracy =  0.3903966597077244 0.35833333333333334\n",
      "\n",
      "Hyper-parameters = \n",
      " activation =  tanh \n",
      " solver =  lbfgs \n",
      " learning_rate_init =  0.001 \n",
      " hidden_layer_sizes =  (5, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(train,  test) accuracy =  0.49965205288796105 0.4722222222222222\n",
      "\n",
      "Hyper-parameters = \n",
      " activation =  relu \n",
      " solver =  adam \n",
      " learning_rate_init =  0.001 \n",
      " hidden_layer_sizes =  (3, 2)\n",
      "(train,  test) accuracy =  0.4140570633263744 0.3638888888888889\n",
      "\n",
      "Hyper-parameters = \n",
      " activation =  tanh \n",
      " solver =  adam \n",
      " learning_rate_init =  0.01 \n",
      " hidden_layer_sizes =  (3, 2)\n",
      "(train,  test) accuracy =  0.20668058455114824 0.18055555555555555\n",
      "\n",
      "Hyper-parameters = \n",
      " activation =  identity \n",
      " solver =  sgd \n",
      " learning_rate_init =  0.0001 \n",
      " hidden_layer_sizes =  (3, 2)\n",
      "(train,  test) accuracy =  0.697981906750174 0.7027777777777777\n",
      "\n",
      "Hyper-parameters = \n",
      " activation =  tanh \n",
      " solver =  adam \n",
      " learning_rate_init =  0.0001 \n",
      " hidden_layer_sizes =  (6, 3)\n",
      "(train,  test) accuracy =  0.9046624913013221 0.8194444444444444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "test_accuracy = []\n",
    "validation_accuracy = []\n",
    "train_accuracy = []\n",
    "for i in range(10):\n",
    "    k1 = np.random.randint(0,len(activation))\n",
    "    k2 = np.random.randint(0,len(solvers))\n",
    "    k3 = np.random.randint(0,len(learning_rate))\n",
    "    k4 = np.random.randint(0,len(hidden_layers))\n",
    "    print(\"\\nHyper-parameters = \\n activation = \", activation[k1],    \"\\n solver = \", solvers[k2], \"\\n learning_rate_init = \", learning_rate[k3],         \"\\n hidden_layer_sizes = \", hidden_layers[k4])\n",
    "    #calling the mlp function with random hyper paramters\n",
    "    clf = mlp(activation[k1],solvers[k2],hidden_layers[k4],learning_rate[k3])\n",
    "    #Fitting the data into model\n",
    "    clf.fit(X_train,Y_train)\n",
    "    ## Predicting the values on trained model using train data\n",
    "    predTrain = clf.predict((X_train))\n",
    "    #Calculating the train accuracy\n",
    "    train_accuracy.append(accuracy(Y_train,predTrain))\n",
    "    # Predicting the values on trained model using test data\n",
    "    predTest = clf.predict((X_test))\n",
    "    #Calculating the test accuracy\n",
    "    test_accuracy.append(accuracy(Y_test,predTest))\n",
    "  \n",
    "    print(\"(train,  test) accuracy = \",accuracy(Y_train,predTrain),  accuracy(Y_test,predTest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yfGsLoIOnWm4"
   },
   "source": [
    "#### Plotting the accuracies of  train, test  sets; On x-axis in the graph below (once the cell is executed), is the combination of parameters output by the cell above, in sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "colab_type": "code",
    "id": "zbPs4aACnWm7",
    "outputId": "e5847ebd-40c6-4c1b-e629-85e252ae81c6"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAQuklEQVR4nO3df5BV5X3H8ffXBQpRhBaotiy6jCUq\nJqMhWxMlUzMFE5SOdKaJv2ImJdqd6dSYmqSdzbRjGJzpYNtJ60QmCTEYJ02lVJOWabDE/Oh0pvkh\nq+IPQCo1FNdgWbYRnSYWGb79Y692XXa5F7x3D/vc92tmh/Pj4Z7vPcN+eO5znnNuZCaSpInvlKoL\nkCQ1h4EuSYUw0CWpEAa6JBXCQJekQkyq6sCzZ8/Orq6uqg4vSRPSI488ciAz54y2r7JA7+rqoq+v\nr6rDS9KEFBH/OdY+h1wkqRAGuiQVwkCXpEJUNoYu1fPqq6/S39/PK6+8UnUp42Lq1Kl0dnYyefLk\nqkvRBGWg66TV39/P9OnT6erqIiKqLqelMpPBwUH6+/uZP39+1eVognLIRSetV155hVmzZhUf5gAR\nwaxZs9rm04haw0DXSa0dwvw17fRe1RoGuiQVwjF0TRhdvd9s6uvtWbP8mPsHBwdZsmQJAC+88AId\nHR3MmTN0g97DDz/MlClT6h5j5cqV9Pb2cu655775gqU6DHRpDLNmzWLbtm0ArFq1itNOO41PfepT\nb2iTmWQmp5wy+ofde+65p+V1qlpjdTTqdRhawSEX6Tjt3r2bhQsX8qEPfYgLLriAffv20dPTQ3d3\nNxdccAGrV69+ve173vMetm3bxuHDh5k5cya9vb1ceOGFXHLJJezfv7/Cd6ESGejSCXj66ae59dZb\n2bFjB3PnzmXNmjX09fXx+OOP89BDD7Fjx46j/s7Bgwe57LLLePzxx7nkkktYv359BZWrZAa6dALO\nOeccuru7X1+/7777WLRoEYsWLWLnzp2jBvq0adO44oorAHjnO9/Jnj17xqtctQnH0KUTcOqpp76+\n/Mwzz3DnnXfy8MMPM3PmTG644YZR55MPv4ja0dHB4cOHx6VWtQ976NKb9NJLLzF9+nROP/109u3b\nx5YtW6ouSW3KHromjCpmDTRi0aJFLFy4kPPOO4+zzz6bxYsXV12S2lRkZiUH7u7uTr/gQseyc+dO\nzj///KrLGFft+J4nuvGethgRj2Rm92j7HHKRpEIY6JJUCANdkgphoEtSISbkLJdjPaTpZJ0JIUmt\nZg9dkgoxIXvoalOrZjT59Q4ec3czHp8LsH79eq688krOPPPMN1evVIeBLo2hkcfnNmL9+vUsWrTI\nQFfLGejSCbj33ntZu3Ythw4d4tJLL+Wuu+7iyJEjrFy5km3btpGZ9PT0cMYZZ7Bt2zauueYapk2b\ndlw9e+l4GejScXrqqaf4xje+wfe//30mTZpET08PGzZs4JxzzuHAgQM8+eSTALz44ovMnDmTz33u\nc9x1111cdNFFFVeu0hno0nH69re/zdatW19/fO7Pf/5z5s2bx/vf/3527drFLbfcwvLly3nf+95X\ncaVqNwa6Tkg7Tx3NTD760Y9y++23H7XviSee4MEHH2Tt2rU88MADrFu3roIKdVI41kX8OhfkT5TT\nFqXjtHTpUjZu3MiBAweAodkwe/fuZWBggMzkgx/8IKtXr+bRRx8FYPr06bz88stVlqw20VAPPSKW\nAXcCHcDdmblmxP6zgHuBmbU2vZm5ucm1qt21qFdzvN7+9rfzmc98hqVLl3LkyBEmT57MF77wBTo6\nOrjxxhvJTCKCO+64A4CVK1dy0003eVFULVc30COiA1gLXA70A1sjYlNmDv+OrT8FNmbm5yNiIbAZ\n6GpBvVIlVq1a9Yb166+/nuuvv/6odo899thR266++mquvvrqVpUmva6RIZeLgd2Z+WxmHgI2ACtG\ntEng9NryDOAnzStRktSIRoZc5gLPDVvvB941os0q4FsR8THgVGDpaC8UET1AD8BZZ511vLVqohjr\nYtBJMmQilapZF0WvA76SmZ3AlcBXI+Ko187MdZnZnZndr91CLR1LVd+oVYV2eq9qjUYC/Xlg3rD1\nztq24W4ENgJk5g+AqcDsZhSo9jV16lQGBwfbIugyk8HBQaZOnVp1KZrAGhly2QosiIj5DAX5tcDI\nq0F7gSXAVyLifIYCfaCZhar9dHZ20t/fz8BAe/xTmjp1Kp2dnVWXoQmsbqBn5uGIuBnYwtCUxPWZ\nuT0iVgN9mbkJ+CTwpYi4laELpL+b7dCtUktNnjyZ+fPnV12GNGE0NA+9Nqd884httw1b3gEsbm5p\nkqTj4Z2iklQIA12SCmGgS1Ihynva4jjd1DLW0wZLf9KgpJOXPXRJKoSBLkmFMNAlqRAGuiQVwkCX\npEIY6JJUiPKmLcrnkUttyh66JBXCHvoENdaNTQB7fKS21JbsoUtSIQx0SSqEgS5JhXAMXVKZ2nC2\nl4EuacJycsAbOeQiSYUw0CWpEAa6JBXCQJekQhjoklQIA12SCuG0xWYba+4rFD3/VVL17KFLUiEM\ndEkqhIEuSYUw0CWpEAa6JBXCQJekQhjoklQIA12SCmGgS1IhDHRJKoSBLkmFaCjQI2JZROyKiN0R\n0TtGm6sjYkdEbI+Iv21umZKkeuo+nCsiOoC1wOVAP7A1IjZl5o5hbRYAnwYWZ+ZPI+KXW1WwJGl0\njfTQLwZ2Z+azmXkI2ACsGNHm94C1mflTgMzc39wyJUn1NBLoc4Hnhq3317YN91bgrRHxbxHxw4hY\nNtoLRURPRPRFRN/AwMCJVSxJGlWzLopOAhYA7wWuA74UETNHNsrMdZnZnZndc+bMadKhJUnQWKA/\nD8wbtt5Z2zZcP7ApM1/NzB8D/85QwEuSxkkjgb4VWBAR8yNiCnAtsGlEm39gqHdORMxmaAjm2SbW\nKUmqo26gZ+Zh4GZgC7AT2JiZ2yNidURcVWu2BRiMiB3A94A/yszBVhUtSTpaQ98pmpmbgc0jtt02\nbDmBT9R+JEkV8E5RSSqEgS5JhTDQJakQBrokFcJAl6RCGOiSVAgDXZIKYaBLUiEMdEkqhIEuSYUw\n0CWpEAa6JBXCQJekQhjoklQIA12SCmGgS1IhDHRJKkRD31gk6Whdvd8cc9+eNcvHsRJpiD10SSqE\ngS5JhTDQJakQBrokFcJAl6RCGOiSVAinLUqtsGrGGNsPjm8daiv20CWpEAa6JBXCQJekQhjoklQI\nA12SCmGgS1IhDHRJKoSBLkmFMNAlqRAGuiQVwkCXpEIY6JJUiIYezhURy4A7gQ7g7sxcM0a73wHu\nB349M/uaVqWkUY31vaZ+p2l7qttDj4gOYC1wBbAQuC4iFo7SbjrwceBHzS5SklRfI0MuFwO7M/PZ\nzDwEbABWjNLuduAO4JUm1idJalAjgT4XeG7Yen9t2+siYhEwLzNH//z3/+16IqIvIvoGBgaOu1hJ\n0tje9EXRiDgF+CzwyXptM3NdZnZnZvecOXPe7KElScM0clH0eWDesPXO2rbXTAfeBvxLRACcCWyK\niKu8MKpW8oKg9EaN9NC3AgsiYn5ETAGuBTa9tjMzD2bm7Mzsyswu4IeAYS5J46xuoGfmYeBmYAuw\nE9iYmdsjYnVEXNXqAiVJjWloHnpmbgY2j9h22xht3/vmy5IkHS/vFJWkQhjoklQIA12SCtHQGLqk\nCWbVjGPsOzh+dWhcGegqj2GmNuWQiyQVwkCXpEIY6JJUCANdkgphoEtSIQx0SSqEgS5JhTDQJakQ\nBrokFcJAl6RCGOiSVAgDXZIKYaBLUiEMdEkqhIEuSYUw0CWpEAa6JBXCQJekQhjoklQIA12SCmGg\nS1IhDHRJKoSBLkmFMNAlqRAGuiQVwkCXpEIY6JJUCANdkgphoEtSIQx0SSqEgS5JhTDQJakQDQV6\nRCyLiF0RsTsiekfZ/4mI2BERT0TEdyLi7OaXKkk6lkn1GkREB7AWuBzoB7ZGxKbM3DGs2WNAd2b+\nLCJ+H/hz4JpWFCzp5NHV+81Rt+9Zs3ycKxE01kO/GNidmc9m5iFgA7BieIPM/F5m/qy2+kOgs7ll\nSpLqaSTQ5wLPDVvvr20by43Ag6PtiIieiOiLiL6BgYHGq5Qk1dXUi6IRcQPQDfzFaPszc11mdmdm\n95w5c5p5aElqe3XH0IHngXnD1jtr294gIpYCfwJclpn/25zyJEmNaqSHvhVYEBHzI2IKcC2waXiD\niHgH8EXgqszc3/wyJUn11O2hZ+bhiLgZ2AJ0AOszc3tErAb6MnMTQ0MspwF/HxEAezPzqhbWLelk\ntmrGMfYdHL862kwjQy5k5mZg84httw1bXtrkuiRJx8k7RSWpEAa6JBXCQJekQhjoklQIA12SCmGg\nS1IhDHRJKoSBLkmFMNAlqRAGuiQVwkCXpEIY6JJUCANdkgphoEtSIQx0SSqEgS5JhTDQJakQBrok\nFcJAl6RCGOiSVAgDXZIKYaBLUiEMdEkqhIEuSYUw0CWpEAa6JBXCQJekQhjoklQIA12SCmGgS1Ih\nDHRJKoSBLkmFMNAlqRAGuiQVwkCXpEIY6JJUCANdkgrRUKBHxLKI2BURuyOid5T9vxARf1fb/6OI\n6Gp2oZKkY6sb6BHRAawFrgAWAtdFxMIRzW4EfpqZvwb8FXBHswuVJB1bIz30i4HdmflsZh4CNgAr\nRrRZAdxbW74fWBIR0bwyJUn1RGYeu0HEB4BlmXlTbf3DwLsy8+ZhbZ6qtemvrf9Hrc2BEa/VA/TU\nVs8FdjXrjZykZgMH6rYqm+fAcwCeg2a+/7Mzc85oOyY16QANycx1wLrxPGaVIqIvM7urrqNKngPP\nAXgOxuv9NzLk8jwwb9h6Z23bqG0iYhIwAxhsRoGSpMY0EuhbgQURMT8ipgDXAptGtNkEfKS2/AHg\nu1lvLEeS1FR1h1wy83BE3AxsATqA9Zm5PSJWA32ZuQn4MvDViNgN/DdDoa82Gl46Bs+B5wA8B+Py\n/uteFJUkTQzeKSpJhTDQJakQBnoLRMS8iPheROyIiO0R8fGqa6pCRHRExGMR8U9V11KFiJgZEfdH\nxNMRsTMiLqm6pvEWEbfWfgeeioj7ImJq1TW1WkSsj4j9tftzXtv2SxHxUEQ8U/vzF1txbAO9NQ4D\nn8zMhcC7gT8Y5XEJ7eDjwM6qi6jQncA/Z+Z5wIW02bmIiLnALUB3Zr6NoUkV7TBh4ivAshHbeoHv\nZOYC4Du19aYz0FsgM/dl5qO15ZcZ+kWeW21V4ysiOoHlwN1V11KFiJgB/AZDM8DIzEOZ+WK1VVVi\nEjCtdn/KW4CfVFxPy2XmvzI022+44Y9HuRf47VYc20BvsdqTJ98B/KjaSsbdXwN/DBypupCKzAcG\ngHtqw053R8SpVRc1njLzeeAvgb3APuBgZn6r2qoqc0Zm7qstvwCc0YqDGOgtFBGnAQ8Af5iZL1Vd\nz3iJiN8C9mfmI1XXUqFJwCLg85n5DuB/aNHH7JNVbZx4BUP/uf0qcGpE3FBtVdWr3XTZkvniBnqL\nRMRkhsL8a5n59arrGWeLgasiYg9DT+f8zYj4m2pLGnf9QH9mvvbJ7H6GAr6dLAV+nJkDmfkq8HXg\n0oprqsp/RcSvANT+3N+KgxjoLVB7dPCXgZ2Z+dmq6xlvmfnpzOzMzC6GLoJ9NzPbqmeWmS8Az0XE\nubVNS4AdFZZUhb3AuyPiLbXfiSW02YXhYYY/HuUjwD+24iAGemssBj7MUM90W+3nyqqL0rj7GPC1\niHgCuAj4s4rrGVe1Tyf3A48CTzKUN8U/AiAi7gN+AJwbEf0RcSOwBrg8Ip5h6JPLmpYc21v/JakM\n9tAlqRAGuiQVwkCXpEIY6JJUCANdkgphoEtSIQx0SSrE/wE0hlzUTMQ5fwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Plotting the data\n",
    "xx = np.array(range(1,11))\n",
    "plt.bar(xx-0.2,train_accuracy,width=0.2)\n",
    "plt.bar(xx,test_accuracy,width=0.2)\n",
    "plt.legend([\"Train\",\"Test\"])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "011_MLP_MNIST_C.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
